"""
è¯­éŸ³åŠ©æ‰‹WebSocket API
æä¾›å®æ—¶çš„è¯­éŸ³å¤„ç†æœåŠ¡
"""
import asyncio
import json
import numpy as np
from typing import Dict, Any
from fastapi import FastAPI, WebSocket, WebSocketDisconnect
from fastapi.responses import HTMLResponse
from loguru import logger

from backend.core.voice_assistant_pipeline import VoiceAssistantPipeline, PipelineEvent


class VoiceAssistantWebSocketAPI:
    """è¯­éŸ³åŠ©æ‰‹WebSocket API"""
    
    def __init__(self):
        self.app = FastAPI(title="è¯­éŸ³åŠ©æ‰‹API", version="1.0.0")
        self.pipeline = VoiceAssistantPipeline()
        self.active_connections: Dict[str, WebSocket] = {}
        
        # è®¾ç½®æµæ°´çº¿äº‹ä»¶å¤„ç†
        self.pipeline.add_event_callback(self.on_pipeline_event)
        
        # è®¾ç½®è·¯ç”±
        self.setup_routes()
    
    def setup_routes(self):
        """è®¾ç½®è·¯ç”±"""
        
        @self.app.get("/")
        async def get_homepage():
            """è¿”å›æ¼”ç¤ºé¡µé¢"""
            return HTMLResponse(content=self.get_demo_html())
        
        @self.app.websocket("/ws/{client_id}")
        async def websocket_endpoint(websocket: WebSocket, client_id: str):
            """WebSocketç«¯ç‚¹"""
            await websocket.accept()
            self.active_connections[client_id] = websocket
            
            logger.info(f"å®¢æˆ·ç«¯ {client_id} å·²è¿æ¥")
            
            try:
                # å‘é€è¿æ¥æˆåŠŸæ¶ˆæ¯
                await websocket.send_text(json.dumps({
                    "type": "connected",
                    "message": "è¿æ¥æˆåŠŸ",
                    "client_id": client_id
                }))
                
                # å¯åŠ¨æµæ°´çº¿
                await self.pipeline.start_pipeline()
                
                while True:
                    try:
                        # æ¥æ”¶éŸ³é¢‘æ•°æ®
                        data = await websocket.receive_bytes()
                        
                        # å°†å­—èŠ‚æ•°æ®è½¬æ¢ä¸ºnumpyæ•°ç»„
                        audio_data = np.frombuffer(data, dtype=np.float32)
                        
                        # æ·»åŠ è°ƒè¯•æ—¥å¿—
                        logger.debug(f"æ”¶åˆ°éŸ³é¢‘æ•°æ®: {len(audio_data)} æ ·æœ¬, èŒƒå›´: [{audio_data.min():.3f}, {audio_data.max():.3f}]")
                        
                        # å¤„ç†éŸ³é¢‘æ•°æ®
                        await self.pipeline.process_audio_chunk(audio_data)
                        
                    except Exception as e:
                        logger.error(f"å¤„ç†éŸ³é¢‘æ•°æ®æ—¶å‡ºé”™: {e}")
                        # ç»§ç»­å¤„ç†ï¼Œä¸ä¸­æ–­è¿æ¥
                    
            except WebSocketDisconnect:
                logger.info(f"å®¢æˆ·ç«¯ {client_id} æ–­å¼€è¿æ¥")
                await self.pipeline.stop_pipeline()
            except Exception as e:
                logger.error(f"WebSocketé”™è¯¯: {e}")
                await websocket.close()
            finally:
                if client_id in self.active_connections:
                    del self.active_connections[client_id]
        
        @self.app.get("/api/status")
        async def get_status():
            """è·å–æµæ°´çº¿çŠ¶æ€"""
            return self.pipeline.get_pipeline_status()
        
        @self.app.post("/api/start")
        async def start_pipeline():
            """å¯åŠ¨æµæ°´çº¿"""
            await self.pipeline.start_pipeline()
            return {"message": "æµæ°´çº¿å·²å¯åŠ¨"}
        
        @self.app.post("/api/stop")
        async def stop_pipeline():
            """åœæ­¢æµæ°´çº¿"""
            await self.pipeline.stop_pipeline()
            return {"message": "æµæ°´çº¿å·²åœæ­¢"}
    
    def on_pipeline_event(self, event: PipelineEvent):
        """å¤„ç†æµæ°´çº¿äº‹ä»¶"""
        # å‘æ‰€æœ‰è¿æ¥çš„å®¢æˆ·ç«¯å¹¿æ’­äº‹ä»¶
        message = {
            "type": "pipeline_event",
            "event_type": event.event_type,
            "data": event.data,
            "state": event.state.value,
            "timestamp": event.timestamp
        }
        
        # å¼‚æ­¥å‘é€æ¶ˆæ¯
        asyncio.create_task(self.broadcast_message(message))
    
    async def broadcast_message(self, message: Dict[str, Any]):
        """å¹¿æ’­æ¶ˆæ¯ç»™æ‰€æœ‰è¿æ¥çš„å®¢æˆ·ç«¯"""
        if not self.active_connections:
            return
        
        disconnected_clients = []
        
        for client_id, websocket in self.active_connections.items():
            try:
                await websocket.send_text(json.dumps(message))
            except Exception as e:
                logger.error(f"å‘é€æ¶ˆæ¯åˆ°å®¢æˆ·ç«¯ {client_id} å¤±è´¥: {e}")
                disconnected_clients.append(client_id)
        
        # æ¸…ç†æ–­å¼€çš„è¿æ¥
        for client_id in disconnected_clients:
            del self.active_connections[client_id]
    
    def get_demo_html(self) -> str:
        """è·å–æ¼”ç¤ºé¡µé¢HTML"""
        return """
<!DOCTYPE html>
<html>
<head>
    <title>è¯­éŸ³åŠ©æ‰‹æ¼”ç¤º</title>
    <meta charset="utf-8">
    <style>
        body {
            font-family: Arial, sans-serif;
            max-width: 800px;
            margin: 0 auto;
            padding: 20px;
            background-color: #f5f5f5;
        }
        .container {
            background: white;
            padding: 20px;
            border-radius: 10px;
            box-shadow: 0 2px 10px rgba(0,0,0,0.1);
        }
        .status {
            padding: 10px;
            margin: 10px 0;
            border-radius: 5px;
            font-weight: bold;
        }
        .status.listening { background-color: #e3f2fd; color: #1976d2; }
        .status.processing { background-color: #fff3e0; color: #f57c00; }
        .status.speaking { background-color: #e8f5e8; color: #388e3c; }
        .status.idle { background-color: #f3e5f5; color: #7b1fa2; }
        
        .controls {
            margin: 20px 0;
        }
        button {
            padding: 10px 20px;
            margin: 5px;
            border: none;
            border-radius: 5px;
            cursor: pointer;
            font-size: 16px;
        }
        .start-btn { background-color: #4caf50; color: white; }
        .stop-btn { background-color: #f44336; color: white; }
        .record-btn { background-color: #2196f3; color: white; }
        
        .log {
            background-color: #f8f8f8;
            border: 1px solid #ddd;
            padding: 10px;
            height: 300px;
            overflow-y: auto;
            font-family: monospace;
            font-size: 12px;
        }
        
        .log-entry {
            margin: 2px 0;
            padding: 2px 5px;
            border-radius: 3px;
        }
        .log-info { background-color: #e3f2fd; }
        .log-success { background-color: #e8f5e8; }
        .log-warning { background-color: #fff3e0; }
        .log-error { background-color: #ffebee; }
    </style>
</head>
<body>
    <div class="container">
        <h1>ğŸ¯ è¯­éŸ³åŠ©æ‰‹æ¼”ç¤º</h1>
        
        <div id="status" class="status idle">
            çŠ¶æ€: ç©ºé—²
        </div>
        
        <div class="controls">
            <button id="connectBtn" class="start-btn">è¿æ¥</button>
            <button id="disconnectBtn" class="stop-btn" disabled>æ–­å¼€</button>
            <button id="recordBtn" class="record-btn" disabled>å¼€å§‹å½•éŸ³</button>
        </div>
        
        <div>
            <h3>äº‹ä»¶æ—¥å¿—</h3>
            <div id="log" class="log"></div>
        </div>
    </div>

    <script>
        let ws = null;
        let mediaRecorder = null;
        let audioContext = null;
        let isRecording = false;
        
        const statusEl = document.getElementById('status');
        const logEl = document.getElementById('log');
        const connectBtn = document.getElementById('connectBtn');
        const disconnectBtn = document.getElementById('disconnectBtn');
        const recordBtn = document.getElementById('recordBtn');
        
        function log(message, type = 'info') {
            const entry = document.createElement('div');
            entry.className = `log-entry log-${type}`;
            entry.textContent = `[${new Date().toLocaleTimeString()}] ${message}`;
            logEl.appendChild(entry);
            logEl.scrollTop = logEl.scrollHeight;
        }
        
        function updateStatus(state, message = '') {
            statusEl.className = `status ${state}`;
            statusEl.textContent = `çŠ¶æ€: ${message || state}`;
        }
        
        connectBtn.onclick = function() {
            const clientId = 'client_' + Date.now();
            ws = new WebSocket(`ws://192.168.73.130:8000/ws/${clientId}`);
            
            ws.onopen = function() {
                log('WebSocketè¿æ¥å·²å»ºç«‹', 'success');
                connectBtn.disabled = true;
                disconnectBtn.disabled = false;
                recordBtn.disabled = false;
            };
            
            ws.onmessage = function(event) {
                const data = JSON.parse(event.data);
                
                if (data.type === 'connected') {
                    log(`è¿æ¥æˆåŠŸï¼Œå®¢æˆ·ç«¯ID: ${data.client_id}`, 'success');
                } else if (data.type === 'pipeline_event') {
                    log(`æµæ°´çº¿äº‹ä»¶: ${data.event_type} - ${data.state}`, 'info');
                    
                    // æ›´æ–°çŠ¶æ€æ˜¾ç¤º
                    switch(data.state) {
                        case 'listening':
                            updateStatus('listening', 'ç›‘å¬ä¸­...');
                            break;
                        case 'speech_recognition':
                            updateStatus('processing', 'è¯­éŸ³è¯†åˆ«ä¸­...');
                            break;
                        case 'intent_processing':
                            updateStatus('processing', 'æ„å›¾è¯†åˆ«ä¸­...');
                            break;
                        case 'executing_command':
                            updateStatus('processing', 'æ‰§è¡ŒæŒ‡ä»¤ä¸­...');
                            break;
                        case 'speaking':
                            updateStatus('speaking', 'è¯­éŸ³åˆæˆä¸­...');
                            break;
                        case 'idle':
                            updateStatus('idle', 'ç©ºé—²');
                            break;
                    }
                    
                    // æ˜¾ç¤ºå…·ä½“ä¿¡æ¯
                    if (data.event_type === 'wake_word_detected') {
                        log(`ğŸ¯ æ£€æµ‹åˆ°å”¤é†’è¯: ${data.data.keyword}`, 'success');
                    } else if (data.event_type === 'intent_processing_started') {
                        log(`ğŸ§  è¯†åˆ«æ–‡æœ¬: ${data.data.text}`, 'info');
                    } else if (data.event_type === 'tts_started') {
                        log(`ğŸ”Š å›å¤: ${data.data.response}`, 'success');
                    }
                }
            };
            
            ws.onclose = function() {
                log('WebSocketè¿æ¥å·²å…³é—­', 'warning');
                connectBtn.disabled = false;
                disconnectBtn.disabled = true;
                recordBtn.disabled = true;
                updateStatus('idle', 'å·²æ–­å¼€');
            };
            
            ws.onerror = function(error) {
                log(`WebSocketé”™è¯¯: ${error}`, 'error');
            };
        };
        
        disconnectBtn.onclick = function() {
            if (ws) {
                ws.close();
            }
            if (isRecording) {
                stopRecording();
            }
        };
        
        recordBtn.onclick = function() {
            if (!isRecording) {
                startRecording();
            } else {
                stopRecording();
            }
        };
        
        async function startRecording() {
            try {
                const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
                audioContext = new AudioContext({ sampleRate: 16000 });
                const source = audioContext.createMediaStreamSource(stream);
                
                // ä½¿ç”¨æ›´å°çš„ç¼“å†²åŒºå¤§å°ï¼Œæé«˜å®æ—¶æ€§
                const processor = audioContext.createScriptProcessor(1024, 1, 1);
                processor.onaudioprocess = function(e) {
                    if (ws && ws.readyState === WebSocket.OPEN) {
                        const audioData = e.inputBuffer.getChannelData(0);
                        
                        // æ£€æŸ¥éŸ³é¢‘æ•°æ®æ˜¯å¦æœ‰æ•ˆ
                        const hasAudio = audioData.some(sample => Math.abs(sample) > 0.001);
                        if (hasAudio) {
                            // è½¬æ¢ä¸ºFloat32Arrayå¹¶å‘é€
                            const buffer = new Float32Array(audioData);
                            try {
                                ws.send(buffer.buffer);
                            } catch (error) {
                                console.error('å‘é€éŸ³é¢‘æ•°æ®å¤±è´¥:', error);
                            }
                        }
                    }
                };
                
                source.connect(processor);
                processor.connect(audioContext.destination);
                
                isRecording = true;
                recordBtn.textContent = 'åœæ­¢å½•éŸ³';
                recordBtn.style.backgroundColor = '#f44336';
                log('å¼€å§‹å½•éŸ³...', 'info');
                
            } catch (error) {
                log(`å½•éŸ³å¯åŠ¨å¤±è´¥: ${error}`, 'error');
            }
        }
        
        function stopRecording() {
            if (audioContext) {
                audioContext.close();
                audioContext = null;
            }
            
            isRecording = false;
            recordBtn.textContent = 'å¼€å§‹å½•éŸ³';
            recordBtn.style.backgroundColor = '#2196f3';
            log('å½•éŸ³å·²åœæ­¢', 'info');
        }
    </script>
</body>
</html>
        """


# åˆ›å»ºAPIå®ä¾‹
api = VoiceAssistantWebSocketAPI()

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(api.app, host="0.0.0.0", port=8000)
