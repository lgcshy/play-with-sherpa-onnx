"""
è¯­éŸ³åŠ©æ‰‹æµæ°´çº¿ç®¡ç†å™¨
å®ç°å®Œæ•´çš„è¯­éŸ³å¤„ç†æµç¨‹ï¼šVAD -> KWS -> ASR -> æ„å›¾è¯†åˆ« -> æ‰§è¡ŒæŒ‡ä»¤ -> TTS
"""
import asyncio
import numpy as np
from enum import Enum
from typing import Optional, Dict, Any, Callable, List
from dataclasses import dataclass
from loguru import logger
import time

from .vad_detector import SileroVAD
from .keyword_spotter import KeywordSpotter


class PipelineState(Enum):
    """æµæ°´çº¿çŠ¶æ€"""
    IDLE = "idle"                    # ç©ºé—²çŠ¶æ€
    LISTENING = "listening"          # ç›‘å¬çŠ¶æ€ï¼ˆVADæ£€æµ‹ï¼‰
    WAKE_WORD_DETECTED = "wake_word_detected"  # å”¤é†’è¯æ£€æµ‹åˆ°
    SPEECH_RECOGNITION = "speech_recognition"  # è¯­éŸ³è¯†åˆ«ä¸­
    INTENT_PROCESSING = "intent_processing"    # æ„å›¾å¤„ç†ä¸­
    EXECUTING_COMMAND = "executing_command"    # æ‰§è¡ŒæŒ‡ä»¤ä¸­
    SPEAKING = "speaking"            # è¯­éŸ³åˆæˆæ’­æ”¾ä¸­


@dataclass
class PipelineEvent:
    """æµæ°´çº¿äº‹ä»¶"""
    event_type: str
    data: Any
    timestamp: float
    state: PipelineState


class ASRModule:
    """è¯­éŸ³è¯†åˆ«æ¨¡å—ï¼ˆå ä½ç¬¦å®ç°ï¼‰"""
    
    def __init__(self):
        self.is_processing = False
        self.current_text = ""
    
    async def start_recognition(self) -> str:
        """å¼€å§‹è¯­éŸ³è¯†åˆ«"""
        logger.info("ğŸ¤ å¼€å§‹è¯­éŸ³è¯†åˆ«...")
        self.is_processing = True
        self.current_text = ""
        
        # æ¨¡æ‹Ÿè¯­éŸ³è¯†åˆ«è¿‡ç¨‹
        await asyncio.sleep(2.0)  # æ¨¡æ‹Ÿè¯†åˆ«æ—¶é—´
        
        # æ¨¡æ‹Ÿè¯†åˆ«ç»“æœ
        sample_texts = [
            "ä»Šå¤©å¤©æ°”æ€ä¹ˆæ ·",
            "æ’­æ”¾éŸ³ä¹",
            "è®¾ç½®é—¹é’Ÿ",
            "æ‰“å¼€ç¯",
            "å…³é—­ç©ºè°ƒ"
        ]
        self.current_text = np.random.choice(sample_texts)
        
        logger.info(f"ğŸ¤ è¯­éŸ³è¯†åˆ«ç»“æœ: {self.current_text}")
        self.is_processing = False
        return self.current_text
    
    def stop_recognition(self):
        """åœæ­¢è¯­éŸ³è¯†åˆ«"""
        self.is_processing = False
        logger.info("ğŸ¤ è¯­éŸ³è¯†åˆ«å·²åœæ­¢")


class IntentModule:
    """æ„å›¾è¯†åˆ«æ¨¡å—ï¼ˆå ä½ç¬¦å®ç°ï¼‰"""
    
    def __init__(self):
        self.intent_patterns = {
            "weather": ["å¤©æ°”", "æ¸©åº¦", "ä¸‹é›¨", "æ™´å¤©"],
            "music": ["æ’­æ”¾", "éŸ³ä¹", "æ­Œæ›²", "å¬æ­Œ"],
            "alarm": ["é—¹é’Ÿ", "æé†’", "å®šæ—¶"],
            "smart_home": ["å¼€ç¯", "å…³ç¯", "ç©ºè°ƒ", "é£æ‰‡"],
            "general": ["ä½ å¥½", "è°¢è°¢", "å†è§"]
        }
    
    async def recognize_intent(self, text: str) -> Dict[str, Any]:
        """è¯†åˆ«æ„å›¾"""
        logger.info(f"ğŸ§  æ„å›¾è¯†åˆ«: {text}")
        
        # ç®€å•çš„å…³é”®è¯åŒ¹é…
        intent = "general"
        confidence = 0.5
        
        for intent_type, keywords in self.intent_patterns.items():
            for keyword in keywords:
                if keyword in text:
                    intent = intent_type
                    confidence = 0.9
                    break
        
        result = {
            "intent": intent,
            "confidence": confidence,
            "text": text,
            "entities": self._extract_entities(text)
        }
        
        logger.info(f"ğŸ§  æ„å›¾è¯†åˆ«ç»“æœ: {result}")
        return result
    
    def _extract_entities(self, text: str) -> Dict[str, str]:
        """æå–å®ä½“"""
        entities = {}
        
        # ç®€å•çš„æ—¶é—´æå–
        if "ç‚¹" in text or "æ—¶" in text:
            entities["time"] = "æå–çš„æ—¶é—´"
        
        # ç®€å•çš„è®¾å¤‡æå–
        devices = ["ç¯", "ç©ºè°ƒ", "é£æ‰‡", "ç”µè§†"]
        for device in devices:
            if device in text:
                entities["device"] = device
                break
        
        return entities


class CommandExecutor:
    """æŒ‡ä»¤æ‰§è¡Œæ¨¡å—ï¼ˆå ä½ç¬¦å®ç°ï¼‰"""
    
    def __init__(self):
        self.command_handlers = {
            "weather": self._handle_weather,
            "music": self._handle_music,
            "alarm": self._handle_alarm,
            "smart_home": self._handle_smart_home,
            "general": self._handle_general
        }
    
    async def execute_command(self, intent_result: Dict[str, Any]) -> Dict[str, Any]:
        """æ‰§è¡ŒæŒ‡ä»¤"""
        intent = intent_result["intent"]
        text = intent_result["text"]
        
        logger.info(f"âš¡ æ‰§è¡ŒæŒ‡ä»¤: {intent} - {text}")
        
        handler = self.command_handlers.get(intent, self._handle_general)
        result = await handler(intent_result)
        
        logger.info(f"âš¡ æŒ‡ä»¤æ‰§è¡Œå®Œæˆ: {result}")
        return result
    
    async def _handle_weather(self, intent_result: Dict[str, Any]) -> Dict[str, Any]:
        """å¤„ç†å¤©æ°”æŸ¥è¯¢"""
        await asyncio.sleep(1.0)  # æ¨¡æ‹ŸAPIè°ƒç”¨
        return {
            "success": True,
            "response": "ä»Šå¤©å¤©æ°”æ™´æœ—ï¼Œæ¸©åº¦25åº¦",
            "action": "weather_query"
        }
    
    async def _handle_music(self, intent_result: Dict[str, Any]) -> Dict[str, Any]:
        """å¤„ç†éŸ³ä¹æ’­æ”¾"""
        await asyncio.sleep(0.5)
        return {
            "success": True,
            "response": "æ­£åœ¨æ’­æ”¾éŸ³ä¹",
            "action": "play_music"
        }
    
    async def _handle_alarm(self, intent_result: Dict[str, Any]) -> Dict[str, Any]:
        """å¤„ç†é—¹é’Ÿè®¾ç½®"""
        await asyncio.sleep(0.5)
        return {
            "success": True,
            "response": "é—¹é’Ÿå·²è®¾ç½®",
            "action": "set_alarm"
        }
    
    async def _handle_smart_home(self, intent_result: Dict[str, Any]) -> Dict[str, Any]:
        """å¤„ç†æ™ºèƒ½å®¶å±…æ§åˆ¶"""
        await asyncio.sleep(0.5)
        device = intent_result.get("entities", {}).get("device", "è®¾å¤‡")
        return {
            "success": True,
            "response": f"{device}å·²æ§åˆ¶",
            "action": "smart_home_control"
        }
    
    async def _handle_general(self, intent_result: Dict[str, Any]) -> Dict[str, Any]:
        """å¤„ç†ä¸€èˆ¬å¯¹è¯"""
        await asyncio.sleep(0.3)
        return {
            "success": True,
            "response": "æˆ‘æ˜ç™½äº†ï¼Œæœ‰ä»€ä¹ˆå¯ä»¥å¸®åŠ©æ‚¨çš„å—ï¼Ÿ",
            "action": "general_chat"
        }


class TTSModule:
    """è¯­éŸ³åˆæˆæ¨¡å—ï¼ˆå ä½ç¬¦å®ç°ï¼‰"""
    
    def __init__(self):
        self.is_speaking = False
    
    async def speak(self, text: str) -> bool:
        """è¯­éŸ³åˆæˆ"""
        logger.info(f"ğŸ”Š è¯­éŸ³åˆæˆ: {text}")
        self.is_speaking = True
        
        # æ¨¡æ‹ŸTTSå¤„ç†æ—¶é—´
        await asyncio.sleep(len(text) * 0.1)  # æ ¹æ®æ–‡æœ¬é•¿åº¦æ¨¡æ‹Ÿæ—¶é—´
        
        logger.info(f"ğŸ”Š è¯­éŸ³æ’­æ”¾å®Œæˆ")
        self.is_speaking = False
        return True
    
    def stop_speaking(self):
        """åœæ­¢è¯­éŸ³æ’­æ”¾"""
        self.is_speaking = False
        logger.info("ğŸ”Š è¯­éŸ³æ’­æ”¾å·²åœæ­¢")


class VoiceAssistantPipeline:
    """è¯­éŸ³åŠ©æ‰‹æµæ°´çº¿ç®¡ç†å™¨"""
    
    def __init__(self, model_dir: str = None):
        """
        åˆå§‹åŒ–è¯­éŸ³åŠ©æ‰‹æµæ°´çº¿
        
        Args:
            model_dir: æ¨¡å‹ç›®å½•è·¯å¾„
        """
        self.model_dir = model_dir
        
        # åˆå§‹åŒ–å„ä¸ªæ¨¡å—
        self.vad = SileroVAD(model_dir)
        self.kws = KeywordSpotter(model_dir)
        self.asr = ASRModule()
        self.intent = IntentModule()
        self.executor = CommandExecutor()
        self.tts = TTSModule()
        
        # æµæ°´çº¿çŠ¶æ€
        self.state = PipelineState.IDLE
        self.is_running = False
        
        # äº‹ä»¶å›è°ƒ
        self.event_callbacks: List[Callable[[PipelineEvent], None]] = []
        
        # éŸ³é¢‘æµ
        self.kws_stream = None
        
        logger.info("ğŸ¯ è¯­éŸ³åŠ©æ‰‹æµæ°´çº¿åˆå§‹åŒ–å®Œæˆ")
    
    def add_event_callback(self, callback: Callable[[PipelineEvent], None]):
        """æ·»åŠ äº‹ä»¶å›è°ƒ"""
        self.event_callbacks.append(callback)
    
    def _emit_event(self, event_type: str, data: Any):
        """å‘é€äº‹ä»¶"""
        event = PipelineEvent(
            event_type=event_type,
            data=data,
            timestamp=time.time(),
            state=self.state
        )
        
        for callback in self.event_callbacks:
            try:
                callback(event)
            except Exception as e:
                logger.error(f"äº‹ä»¶å›è°ƒé”™è¯¯: {e}")
    
    async def start_pipeline(self):
        """å¯åŠ¨æµæ°´çº¿"""
        if self.is_running:
            logger.warning("æµæ°´çº¿å·²åœ¨è¿è¡Œä¸­")
            return
        
        self.is_running = True
        self.state = PipelineState.LISTENING
        self.kws_stream = self.kws.create_stream()
        
        logger.info("ğŸ¯ è¯­éŸ³åŠ©æ‰‹æµæ°´çº¿å¯åŠ¨")
        self._emit_event("pipeline_started", {"state": self.state.value})
        
        # å¼€å§‹ç›‘å¬å¾ªç¯
        await self._listening_loop()
    
    async def stop_pipeline(self):
        """åœæ­¢æµæ°´çº¿"""
        self.is_running = False
        self.state = PipelineState.IDLE
        
        # åœæ­¢å„ä¸ªæ¨¡å—
        self.asr.stop_recognition()
        self.tts.stop_speaking()
        
        logger.info("ğŸ¯ è¯­éŸ³åŠ©æ‰‹æµæ°´çº¿åœæ­¢")
        self._emit_event("pipeline_stopped", {"state": self.state.value})
    
    async def process_audio_chunk(self, audio_data: np.ndarray, sample_rate: int = 16000):
        """å¤„ç†éŸ³é¢‘æ•°æ®å—"""
        if not self.is_running:
            logger.warning("âš ï¸ æµæ°´çº¿æœªè¿è¡Œï¼Œå¿½ç•¥éŸ³é¢‘æ•°æ®")
            return
        
        try:
            if self.state == PipelineState.LISTENING:
                await self._handle_listening_state(audio_data, sample_rate)
            elif self.state == PipelineState.SPEECH_RECOGNITION:
                # åœ¨è¯­éŸ³è¯†åˆ«çŠ¶æ€ä¸‹ï¼Œå¯ä»¥ç»§ç»­æ”¶é›†éŸ³é¢‘æ•°æ®
                logger.debug("è¯­éŸ³è¯†åˆ«çŠ¶æ€ï¼Œç»§ç»­æ”¶é›†éŸ³é¢‘æ•°æ®")
            else:
                logger.debug(f"å½“å‰çŠ¶æ€: {self.state.value}ï¼Œå¿½ç•¥éŸ³é¢‘æ•°æ®")
            
        except Exception as e:
            logger.error(f"âŒ éŸ³é¢‘å¤„ç†é”™è¯¯: {e}")
            import traceback
            logger.error(f"âŒ é”™è¯¯è¯¦æƒ…: {traceback.format_exc()}")
            try:
                await self._reset_to_listening()
            except Exception as reset_error:
                logger.error(f"âŒ é‡ç½®æµæ°´çº¿å¤±è´¥: {reset_error}")
    
    async def _handle_listening_state(self, audio_data: np.ndarray, sample_rate: int):
        """å¤„ç†ç›‘å¬çŠ¶æ€"""
        # å‡å°‘æ—¥å¿—é¢‘ç‡ - æ¯20ä¸ªéŸ³é¢‘å—è¾“å‡ºä¸€æ¬¡
        if hasattr(self, '_audio_count'):
            self._audio_count += 1
        else:
            self._audio_count = 1
            
        if self._audio_count % 20 == 0:
            logger.info(f"ğŸ”„ å¤„ç†éŸ³é¢‘å—: {len(audio_data)} æ ·æœ¬, èŒƒå›´: [{audio_data.min():.3f}, {audio_data.max():.3f}]")
        
        # é‡æ–°å¯ç”¨VADæ£€æµ‹
        has_speech = self.vad.process_audio_chunk(audio_data, sample_rate)
        
        if self._audio_count % 20 == 0:
            logger.info(f"ğŸ¤ VADæ£€æµ‹ç»“æœ: {has_speech}")
        
        if has_speech:
            if self._audio_count % 20 == 0:
                logger.info("ğŸ¯ æ£€æµ‹åˆ°è¯­éŸ³æ´»åŠ¨ï¼Œè¿›è¡Œå…³é”®è¯æ£€æµ‹...")
            keyword = self.kws.process_audio_chunk(self.kws_stream, audio_data, sample_rate)
            
            if keyword:
                logger.info(f"ğŸ¯ æ£€æµ‹åˆ°å”¤é†’è¯: {keyword}")
                self.state = PipelineState.WAKE_WORD_DETECTED
                self._emit_event("wake_word_detected", {"keyword": keyword})
                
                # è¿›å…¥è¯­éŸ³è¯†åˆ«é˜¶æ®µ
                await self._enter_speech_recognition()
            elif self._audio_count % 20 == 0:
                logger.info("ğŸ¯ KWSæ£€æµ‹ç»“æœ: None")
        else:
            if self._audio_count % 20 == 0:
                logger.info("ğŸ”‡ æœªæ£€æµ‹åˆ°è¯­éŸ³æ´»åŠ¨")
            # å³ä½¿æ²¡æœ‰VADæ£€æµ‹åˆ°è¯­éŸ³ï¼Œä¹Ÿè¿›è¡Œå…³é”®è¯æ£€æµ‹ï¼ˆé™ä½VADä¾èµ–ï¼‰
            keyword = self.kws.process_audio_chunk(self.kws_stream, audio_data, sample_rate)
            if keyword:
                logger.info(f"ğŸ¯ æ£€æµ‹åˆ°å”¤é†’è¯ï¼ˆæ— VADï¼‰: {keyword}")
                self.state = PipelineState.WAKE_WORD_DETECTED
                self._emit_event("wake_word_detected", {"keyword": keyword})
                
                # è¿›å…¥è¯­éŸ³è¯†åˆ«é˜¶æ®µ
                await self._enter_speech_recognition()
    
    async def _enter_speech_recognition(self):
        """è¿›å…¥è¯­éŸ³è¯†åˆ«é˜¶æ®µ"""
        self.state = PipelineState.SPEECH_RECOGNITION
        self._emit_event("speech_recognition_started", {})
        
        # å¼€å§‹è¯­éŸ³è¯†åˆ«
        recognized_text = await self.asr.start_recognition()
        
        if recognized_text:
            # è¿›å…¥æ„å›¾è¯†åˆ«é˜¶æ®µ
            await self._enter_intent_processing(recognized_text)
        else:
            # è¯†åˆ«å¤±è´¥ï¼Œè¿”å›ç›‘å¬çŠ¶æ€
            await self._reset_to_listening()
    
    async def _enter_intent_processing(self, text: str):
        """è¿›å…¥æ„å›¾å¤„ç†é˜¶æ®µ"""
        self.state = PipelineState.INTENT_PROCESSING
        self._emit_event("intent_processing_started", {"text": text})
        
        # è¯†åˆ«æ„å›¾
        intent_result = await self.intent.recognize_intent(text)
        
        # è¿›å…¥æŒ‡ä»¤æ‰§è¡Œé˜¶æ®µ
        await self._enter_command_execution(intent_result)
    
    async def _enter_command_execution(self, intent_result: Dict[str, Any]):
        """è¿›å…¥æŒ‡ä»¤æ‰§è¡Œé˜¶æ®µ"""
        self.state = PipelineState.EXECUTING_COMMAND
        self._emit_event("command_execution_started", intent_result)
        
        # æ‰§è¡ŒæŒ‡ä»¤
        execution_result = await self.executor.execute_command(intent_result)
        
        # è¿›å…¥è¯­éŸ³åˆæˆé˜¶æ®µ
        await self._enter_tts(execution_result)
    
    async def _enter_tts(self, execution_result: Dict[str, Any]):
        """è¿›å…¥è¯­éŸ³åˆæˆé˜¶æ®µ"""
        self.state = PipelineState.SPEAKING
        self._emit_event("tts_started", execution_result)
        
        # è¯­éŸ³åˆæˆ
        response_text = execution_result.get("response", "å¤„ç†å®Œæˆ")
        await self.tts.speak(response_text)
        
        # è¿”å›ç›‘å¬çŠ¶æ€
        await self._reset_to_listening()
    
    async def _reset_to_listening(self):
        """é‡ç½®åˆ°ç›‘å¬çŠ¶æ€"""
        self.state = PipelineState.LISTENING
        self.kws_stream = self.kws.create_stream()  # é‡æ–°åˆ›å»ºæµ
        self.vad.reset()  # é‡ç½®VADçŠ¶æ€
        
        self._emit_event("returned_to_listening", {})
        logger.info("ğŸ”„ è¿”å›ç›‘å¬çŠ¶æ€")
    
    async def _listening_loop(self):
        """ç›‘å¬å¾ªç¯ï¼ˆç”¨äºæ¼”ç¤ºï¼‰"""
        while self.is_running:
            await asyncio.sleep(0.1)  # é¿å…CPUå ç”¨è¿‡é«˜
    
    def get_pipeline_status(self) -> Dict[str, Any]:
        """è·å–æµæ°´çº¿çŠ¶æ€"""
        return {
            "state": self.state.value,
            "is_running": self.is_running,
            "modules": {
                "vad": self.vad.get_model_info(),
                "kws": self.kws.get_model_info(),
                "asr": {"is_processing": self.asr.is_processing},
                "tts": {"is_speaking": self.tts.is_speaking}
            }
        }
